{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys,shutil, random,math,glob\n",
    "import girder_client as gc\n",
    "from pprint import pprint\n",
    "from IPython.display import Image\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "sys.path.append(\"../helperLibs\")\n",
    "from pprint import pprint\n",
    "\n",
    "import DSAHelperFunctions as DSA\n",
    "#import config as c\n",
    "API_URL = \"http://candygram.neurology.emory.edu:8080/api/v1\"\n",
    "dsaGC = gc.GirderClient(apiUrl=API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login or email: admin\n",
      "Password for admin: ········\n"
     ]
    }
   ],
   "source": [
    "dsaGC.authenticate(interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide some info about the data set I am generating\n",
    "testSetSpec = dict(\n",
    "    testSetName = \"TCGA_MultiClass.V1\",\n",
    "    testSetDescription = \"\"\"Set contains DX1 slides; the data set is split into 80/20  training/testing\n",
    "    By Default, it will assume a 256x256 padded thumbnail image output although you can change this if you want\n",
    "    in the download script\"\"\",\n",
    "    defaultMacroSize = 256,\n",
    "    setSource = \"TCGA\",\n",
    "    trainRatio = 0.80,\n",
    "    testRatio= 0.20,\n",
    "    valRatio = 0.00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Go to girder and get the list of images\n",
    "##going to use some of the special tcga endpoints to make my life a little easier\n",
    "## This gets the cancer types and/or cohorts we have data for\n",
    "TCGACohortList = dsaGC.get('/tcga/cohort')\n",
    "cohortData = {}\n",
    "for x in  TCGACohortList['data']:\n",
    "    cohortData[x['lowerName']] = { '_id': x['_id'], 'lowerName': x['lowerName']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KYou have processed 1538 slides and 1538 were DX slides\n",
      "You have found a total of 1538 slides for cohort coad\n",
      "\u001b[KYou have processed 2427 slides and 2427 were DX slides\n",
      "You have found a total of 889 slides for cohort sarc\n",
      "\u001b[KYou have processed 3231 slides and 3231 were DX slides\n",
      "You have found a total of 804 slides for cohort kirp\n",
      "\u001b[KYou have processed 6527 slides and 6527 were DX slides\n",
      "You have found a total of 3296 slides for cohort lgg\n",
      "\u001b[KYou have processed 6845 slides and 6845 were DX slides\n",
      "You have found a total of 318 slides for cohort thym\n",
      "\u001b[KYou have processed 8093 slides and 8093 were DX slides\n",
      "You have found a total of 1248 slides for cohort thca\n",
      "\u001b[KYou have processed 8276 slides and 8276 were DX slides\n",
      "You have found a total of 183 slides for cohort meso\n",
      "\u001b[KYou have processed 8672 slides and 8672 were DX slides\n",
      "You have found a total of 396 slides for cohort esca\n",
      "\u001b[KYou have processed 9234 slides and 9234 were DX slides\n",
      "You have found a total of 562 slides for cohort read\n",
      "\u001b[KYou have processed 9890 slides and 9890 were DX slides\n",
      "You have found a total of 656 slides for cohort cesc\n",
      "\u001b[KYou have processed 11588 slides and 11588 were DX slides\n",
      "You have found a total of 1698 slides for cohort lusc\n",
      "\u001b[KYou have processed 11698 slides and 11698 were DX slides\n",
      "You have found a total of 110 slides for cohort dlbc\n",
      "\u001b[KYou have processed 13919 slides and 13919 were DX slides\n",
      "You have found a total of 2221 slides for cohort kirc\n",
      "\u001b[KYou have processed 14077 slides and 14077 were DX slides\n",
      "You have found a total of 158 slides for cohort ucs\n",
      "\u001b[KYou have processed 15057 slides and 15057 were DX slides\n",
      "You have found a total of 980 slides for cohort skcm\n",
      "\u001b[KYou have processed 15147 slides and 15147 were DX slides\n",
      "You have found a total of 90 slides for cohort chol\n",
      "\u001b[KYou have processed 16498 slides and 16498 were DX slides\n",
      "You have found a total of 1351 slides for cohort hnsc\n",
      "\u001b[KYou have processed 16908 slides and 16908 were DX slides\n",
      "You have found a total of 410 slides for cohort tgct\n",
      "\u001b[KYou have processed 17848 slides and 17848 were DX slides\n",
      "You have found a total of 940 slides for cohort lihc\n",
      "\u001b[KYou have processed 18239 slides and 18239 were DX slides\n",
      "You have found a total of 391 slides for cohort pcpg\n",
      "\u001b[KYou have processed 19838 slides and 19838 were DX slides\n",
      "You have found a total of 1599 slides for cohort ov\n",
      "\u001b[KYou have processed 19995 slides and 19995 were DX slides\n",
      "You have found a total of 157 slides for cohort uvm\n",
      "\u001b[KYou have processed 20318 slides and 20318 were DX slides\n",
      "You have found a total of 323 slides for cohort acc\n",
      "\u001b[KYou have processed 21859 slides and 21859 were DX slides\n",
      "You have found a total of 1541 slides for cohort ucec\n",
      "\u001b[KYou have processed 23102 slides and 23102 were DX slides\n",
      "You have found a total of 1243 slides for cohort prad\n",
      "\u001b[KYou have processed 26921 slides and 26921 were DX slides\n",
      "You have found a total of 3819 slides for cohort brca\n",
      "\u001b[KYou have processed 27927 slides and 27927 were DX slides\n",
      "You have found a total of 1006 slides for cohort blca\n",
      "\u001b[KYou have processed 32864 slides and 32864 were DX slides\n",
      "You have found a total of 4937 slides for cohort gbm\n",
      "\u001b[KYou have processed 34279 slides and 34279 were DX slides\n",
      "You have found a total of 1415 slides for cohort stad\n",
      "\u001b[KYou have processed 35951 slides and 35951 were DX slides\n",
      "You have found a total of 1672 slides for cohort luad\n",
      "\u001b[KYou have processed 36445 slides and 36445 were DX slides\n",
      "You have found a total of 494 slides for cohort paad\n",
      "\u001b[KYou have processed 36780 slides and 36780 were DX slides\n",
      "You have found a total of 335 slides for cohort kich\n"
     ]
    }
   ],
   "source": [
    "### Let's get all of the DX images for our initial test..\n",
    "## get the cases for the cohort, but ONLY am getting the first DX slide...\n",
    "dxSlidesFound = totalSlidesFound =  0\n",
    "\n",
    "for cohort in cohortData:\n",
    "    slideList = dsaGC.get('/tcga/cohort/%s/images?&limit=100000' % cohortData[cohort]['_id'])\n",
    "    \n",
    "    dxSlidesForCohort = []\n",
    "    for sld in slideList['data']:\n",
    "        totalSlidesFound +=1\n",
    "        #if 'DX' in sld['tcga']['barcode']:\n",
    "        dxSlidesFound +=1\n",
    "        dxSlidesForCohort.append(sld)\n",
    "        DSA.LinePrinter(\"You have processed %d slides and %d were DX slides\" % (totalSlidesFound,dxSlidesFound))\n",
    "    \n",
    "    print (\"\\nYou have found a total of %d slides for cohort %s\" % ( len(dxSlidesForCohort),cohort))\n",
    "        \n",
    "    cohortData[cohort]['dxCaseList'] = dxSlidesForCohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_keys( sampleSet, keysToRemove='default' ):\n",
    "    ### There's a lot of extra metadata for each item that is largely irrelevant, so this will for now\n",
    "    ### use a blacklist to remove keys I know are not useful\n",
    "    if (keysToRemove=='default'):\n",
    "        fieldsToPrune = ['description','copyOfItem','folderId','baseParentId','baseParentType','created','creatorId','largeImage','updated','lowerName','size']\n",
    "    ### This is a default set of keys I have not found very helpful..\n",
    "    for s in sampleSet:\n",
    "        for f in fieldsToPrune:\n",
    "            if f in s:\n",
    "                del s[f]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the sample Set, then shuffle it-- \n",
    "## In this case we have no validation data because Keras automagically does it for us\n",
    "def generateTrainTestVal( samples, trainRatio=0.8, testRatio=0.2,valRatio=0,removeExtraKeys = True ):\n",
    "    ### Given a list, this will split it into train,test and validation spots\n",
    "    # This returns a tuple of trainSet, valSet, testSet\n",
    "    shuffle(samples)\n",
    "\n",
    "    ## Split up the original shuffled samples into 3 chunks of diff lengths based on proportions above..\n",
    "    ## Remove extra keys that I don't want to output\n",
    "    if removeExtraKeys:\n",
    "        remove_extra_keys(samples)\n",
    "\n",
    "    N = len(samples)\n",
    "    endTrainingIndex = int(trainRatio*N)\n",
    "    endValidationIndex = int(valRatio*N) + endTrainingIndex\n",
    "    startTestSetIndex = endValidationIndex  ## or -1 or something else..\n",
    "\n",
    "    trainSet = samples[0:endTrainingIndex]\n",
    "    valSet = samples[endTrainingIndex:endValidationIndex]\n",
    "    testSet = samples[startTestSetIndex:]\n",
    "    return (trainSet,valSet,testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coad 1538\n",
      "sarc 889\n",
      "kirp 804\n",
      "lgg 3296\n",
      "thym 318\n",
      "thca 1248\n",
      "meso 183\n",
      "esca 396\n",
      "read 562\n",
      "cesc 656\n",
      "lusc 1698\n",
      "dlbc 110\n",
      "kirc 2221\n",
      "ucs 158\n",
      "skcm 980\n",
      "chol 90\n",
      "hnsc 1351\n",
      "tgct 410\n",
      "lihc 940\n",
      "pcpg 391\n",
      "ov 1599\n",
      "uvm 157\n",
      "acc 323\n",
      "ucec 1541\n",
      "prad 1243\n",
      "brca 3819\n",
      "blca 1006\n",
      "gbm 4937\n",
      "stad 1415\n",
      "luad 1672\n",
      "paad 494\n",
      "kich 335\n"
     ]
    }
   ],
   "source": [
    "## Generate the training and test Sets for all the cohorts... could potentially ignore cohorts if they\n",
    "## Don't have enough images\n",
    "combinedTrainSet = {}\n",
    "combinedTestSet = {}\n",
    "combinedValSet = {}\n",
    "\n",
    "for c in cohortData:\n",
    "    cohortSamples = cohortData[c]['dxCaseList'] \n",
    "    print (c, len(cohortSamples))\n",
    "    cohortTrain,cohortVal,cohortTest = generateTrainTestVal(cohortSamples)\n",
    "    combinedTrainSet[c] = cohortTrain\n",
    "    combinedTestSet[c]  = cohortTest\n",
    "    combinedValSet[c] = cohortVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON meta data set from the above generated TrainSet, TestSet and ValSet\n",
    "testSetSpec['cohortLabels'] = list(combinedTrainSet.keys()) \n",
    "dataSetDefintion = {\"meta\":testSetSpec, \"serverAPIUrl\":API_URL, \"valSet\":combinedValSet, \"trainingSet\": combinedTrainSet, \"testSet\": combinedTestSet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"TCGA.MultiClass.MacroImageSet_256_20k.json\",\"w\") as fp:\n",
    "    json.dump(dataSetDefintion,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(testSetSpec['cohortLabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetSpec['cohortLabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
